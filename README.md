# Automatic Lip Reading using deep learning techniques
## Dataset : MIRACL-VC1 https://sites.google.com/site/achrafbenhamadou/-datasets/miracl-vc1?pli=1
""Fifteen speakers (five men and ten women) positioned in the frustum of a MS Kinect sensor and utter ten times a set of ten words and ten phrases (see the table below). Each instance of the dataset consists of a synchronized sequence of color and depth images (both of 640x480 pixels).  The MIRACL-VC1 dataset contains a total number of 3000 instances.""
![image](https://user-images.githubusercontent.com/38484434/218015842-6dcec60d-2931-4633-b5fd-b25642f93c7b.png)
![image](https://user-images.githubusercontent.com/38484434/218016567-604e449d-bc12-4490-b5eb-000e1f211238.png)

We have limited the scope of the project to only predicting the words. 

## Modules

data_generator.ipynb : Crops lips from face images and store them in the same folder structure as the original.
![image](https://user-images.githubusercontent.com/38484434/218016938-a448ca6c-390f-462c-bc57-ab79a578b1c1.png)
![image](https://user-images.githubusercontent.com/38484434/218016960-d5f2ad66-480c-4592-be29-b5a9153f8f85.png)
