{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Writing frames frame%05d.png.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done writing frames frame%05d.png.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['frame00000.png',\n",
       " 'frame00001.png',\n",
       " 'frame00002.png',\n",
       " 'frame00003.png',\n",
       " 'frame00004.png',\n",
       " 'frame00005.png',\n",
       " 'frame00006.png',\n",
       " 'frame00007.png',\n",
       " 'frame00008.png',\n",
       " 'frame00009.png',\n",
       " 'frame00010.png',\n",
       " 'frame00011.png',\n",
       " 'frame00012.png',\n",
       " 'frame00013.png',\n",
       " 'frame00014.png',\n",
       " 'frame00015.png',\n",
       " 'frame00016.png',\n",
       " 'frame00017.png',\n",
       " 'frame00018.png',\n",
       " 'frame00019.png',\n",
       " 'frame00020.png',\n",
       " 'frame00021.png',\n",
       " 'frame00022.png']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from moviepy.editor import VideoFileClip\n",
    "\n",
    "video = VideoFileClip('D:/Projects/external_data/Previous/20221020_121933.mp4')\n",
    "video.write_images_sequence('frame%05d.png',fps = 10, logger='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import imutils\n",
    "import dlib\n",
    "import cv2 \n",
    "\n",
    "import imageio\n",
    "from imutils import face_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "file_list = os.listdir('D:/Projects/external_data/previous')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_and_save_image(img, img_path, write_img_path, img_name):\n",
    "    detector = dlib.get_frontal_face_detector()\n",
    "    predictor = dlib.shape_predictor('D:/Projects/shape_predictor_68_face_landmarks/shape_predictor_68_face_landmarks/shape_predictor_68_face_landmarks.dat')\n",
    "    # load the input image, resize it, and convert it to grayscale\n",
    "\n",
    "    image = cv2.imread(img_path)\n",
    "    image = imutils.resize(image, width=500)\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # detect faces in the grayscale image\n",
    "    rects = detector(gray, 1)\n",
    "    if len(rects) > 1:\n",
    "        print(\"Error\")\n",
    "        return\n",
    "    if len(rects) < 1:\n",
    "        print( \"ERROR: no faces detected\")\n",
    "        return\n",
    "    for (i, rect) in enumerate(rects):\n",
    "        shape = predictor(gray, rect)\n",
    "        shape = face_utils.shape_to_np(shape)\n",
    "        name, i, j = 'mouth', 48, 68\n",
    "        # clone = gray.copy()\n",
    "        (x, y, w, h) = cv2.boundingRect(np.array([shape[i:j]]))        \n",
    "        roi = gray[y:y+h, x:x+w]\n",
    "        roi = imutils.resize(roi, width = 250, inter=cv2.INTER_CUBIC)        \n",
    "        print( write_img_path)\n",
    "        cv2.imwrite(write_img_path, roi)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\deepdesk\\AppData\\Local\\Temp\\ipykernel_6644\\527829137.py:4: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning dissapear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
      "  image = imageio.imread(directory + '' + img_name)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:/Projects/external_data/previous/cropped/frame00006.png\n",
      "D:/Projects/external_data/previous/cropped/frame00007.png\n",
      "D:/Projects/external_data/previous/cropped/frame00008.png\n",
      "D:/Projects/external_data/previous/cropped/frame00009.png\n",
      "D:/Projects/external_data/previous/cropped/frame00010.png\n",
      "D:/Projects/external_data/previous/cropped/frame00011.png\n",
      "D:/Projects/external_data/previous/cropped/frame00012.png\n",
      "D:/Projects/external_data/previous/cropped/frame00013.png\n",
      "D:/Projects/external_data/previous/cropped/frame00014.png\n",
      "D:/Projects/external_data/previous/cropped/frame00015.png\n",
      "D:/Projects/external_data/previous/cropped/frame00016.png\n",
      "D:/Projects/external_data/previous/cropped/frame00017.png\n",
      "D:/Projects/external_data/previous/cropped/frame00018.png\n",
      "D:/Projects/external_data/previous/cropped/frame00019.png\n",
      "D:/Projects/external_data/previous/cropped/frame00020.png\n"
     ]
    }
   ],
   "source": [
    "directory = 'D:/Projects/external_data/previous/frames/'\n",
    "dir_temp = 'D:/Projects/external_data/previous/cropped/'\n",
    "for img_name in file_list:\n",
    "    image = imageio.imread(directory + '' + img_name)\n",
    "    crop_and_save_image(image, directory + '' + img_name,dir_temp + '' + img_name, img_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading The Saved Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.models import load_model\n",
    "savedModel=load_model('D:/Projects/MIRACL-VC1/models/cnn_adagrad_e45_bc1/model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PreProcessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_seq_length = 22\n",
    "MAX_WIDTH = 100\n",
    "MAX_HEIGHT = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\deepdesk\\AppData\\Local\\Temp\\ipykernel_6644\\3515270067.py:5: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning dissapear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
      "  image = imageio.imread(dir_temp + '/' + img_name)\n"
     ]
    }
   ],
   "source": [
    "from skimage.transform import resize\n",
    "import time\n",
    "sequence = []\n",
    "for img_name in file_list:        \n",
    "    image = imageio.imread(dir_temp + '/' + img_name)\n",
    "    image = resize(image, (MAX_WIDTH, MAX_HEIGHT))\n",
    "    image = 255 * image\n",
    "    # Convert to integer data type pixels.\n",
    "    image = image.astype(np.uint8)\n",
    "    sequence.append(image)                        \n",
    "pad_array = [np.zeros((MAX_WIDTH, MAX_HEIGHT))]                            \n",
    "sequence.extend(pad_array * (max_seq_length - len(sequence)))\n",
    "sequence = np.array(sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_it(X):\n",
    "    v_min = X.min(axis=(2, 3), keepdims=True)\n",
    "    v_max = X.max(axis=(2, 3), keepdims=True)\n",
    "    X = (X - v_min)/(v_max - v_min)\n",
    "    X = np.nan_to_num(X)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\deepdesk\\AppData\\Local\\Temp\\ipykernel_6644\\3382126703.py:4: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X = (X - v_min)/(v_max - v_min)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 3s 3s/step\n",
      "['Stop']\n"
     ]
    }
   ],
   "source": [
    "X_test = []\n",
    "X_test.append(sequence)\n",
    "X_test = np.array(X_test)\n",
    "X_test = normalize_it(X_test)\n",
    "X_test = np.expand_dims(X_test, axis=4)\n",
    "ypred = savedModel.predict(X_test)\n",
    "words = ['Begin', 'Choose', 'Connection', 'Navigation', 'Next', 'Previous', 'Start', 'Stop', 'Hello', 'Web']  \n",
    "predicted_words = [words[i] for i in np.argmax(ypred, axis=1)]\n",
    "print(predicted_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.3020193e-03, 1.1207085e-03, 2.7790403e-03, 1.2108639e-04,\n",
       "        4.1729319e-01, 1.1743272e-04, 1.3977316e-03, 5.7120907e-01,\n",
       "        1.2432352e-05, 4.6472815e-03]], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ypred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# release GPU memory\n",
    "from keras import backend as K\n",
    "K.clear_session()\n",
    "\n",
    "from numba import cuda\n",
    "cuda.select_device(0)\n",
    "cuda.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # import the opencv library\n",
    "# import cv2\n",
    "  \n",
    "  \n",
    "# # define a video capture object\n",
    "# vid = cv2.VideoCapture(0)\n",
    "  \n",
    "# while(True):\n",
    "      \n",
    "#     # Capture the video frame\n",
    "#     # by frame\n",
    "#     ret, frame = vid.read()\n",
    "  \n",
    "#     # Display the resulting frame\n",
    "#     cv2.imshow('frame', frame)\n",
    "      \n",
    "#     # the 'q' button is set as the\n",
    "#     # quitting button you may use any\n",
    "#     # desired button of your choice\n",
    "#     if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "#         break\n",
    "  \n",
    "# # After the loop release the cap object\n",
    "# vid.release()\n",
    "# # Destroy all the windows\n",
    "# cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0398511a9cde84ab83a2fa188ff6508a33d7c0397b3581839dbbf3238a247df4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
