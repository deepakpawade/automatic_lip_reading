{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kG8WT2BZL7H0",
        "outputId": "8a17b4a7-ab6f-47ad-c360-fa3ccaf34c38"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyngrok\n",
            "  Downloading pyngrok-5.1.0.tar.gz (745 kB)\n",
            "\u001b[K     |████████████████████████████████| 745 kB 4.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from pyngrok) (6.0)\n",
            "Building wheels for collected packages: pyngrok\n",
            "  Building wheel for pyngrok (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyngrok: filename=pyngrok-5.1.0-py3-none-any.whl size=19007 sha256=3785d9e968255fd4a3da8156dec0f5cb159aab271a7f97865d7509afc6744642\n",
            "  Stored in directory: /root/.cache/pip/wheels/bf/e6/af/ccf6598ecefecd44104069371795cb9b3afbcd16987f6ccfb3\n",
            "Successfully built pyngrok\n",
            "Installing collected packages: pyngrok\n",
            "Successfully installed pyngrok-5.1.0\n"
          ]
        }
      ],
      "source": [
        "!pip install pyngrok"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oMn5i2kvMC7y",
        "outputId": "4e082c7d-7db7-4170-f64f-3a044c7b4d1c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Authtoken saved to configuration file: /root/.ngrok2/ngrok.yml\n"
          ]
        }
      ],
      "source": [
        "!ngrok authtoken 2HFZwmSnRUIPXem5Q3tVRKEhL7j_3wfvfNz1oFsuH6BQwEUZf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p3agB3IRtt3b",
        "outputId": "f67e3ac7-bb27-4c0e-d77d-e1836ff73282"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting flask-wtf\n",
            "  Downloading Flask_WTF-1.0.1-py3-none-any.whl (12 kB)\n",
            "Requirement already satisfied: Flask in /usr/local/lib/python3.7/dist-packages (from flask-wtf) (1.1.4)\n",
            "Collecting WTForms\n",
            "  Downloading WTForms-3.0.1-py3-none-any.whl (136 kB)\n",
            "\u001b[K     |████████████████████████████████| 136 kB 4.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: itsdangerous in /usr/local/lib/python3.7/dist-packages (from flask-wtf) (1.1.0)\n",
            "Requirement already satisfied: click<8.0,>=5.1 in /usr/local/lib/python3.7/dist-packages (from Flask->flask-wtf) (7.1.2)\n",
            "Requirement already satisfied: Jinja2<3.0,>=2.10.1 in /usr/local/lib/python3.7/dist-packages (from Flask->flask-wtf) (2.11.3)\n",
            "Requirement already satisfied: Werkzeug<2.0,>=0.15 in /usr/local/lib/python3.7/dist-packages (from Flask->flask-wtf) (1.0.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2<3.0,>=2.10.1->Flask->flask-wtf) (2.0.1)\n",
            "Installing collected packages: WTForms, flask-wtf\n",
            "Successfully installed WTForms-3.0.1 flask-wtf-1.0.1\n"
          ]
        }
      ],
      "source": [
        "!pip install flask-wtf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cZd8H4ZluEHt"
      },
      "outputs": [],
      "source": [
        "from pyngrok import ngrok# Open a HTTP tunnel on the default port 80\n",
        "public_url = ngrok.connect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aI5Rz-T_uGG-",
        "outputId": "05f67d03-57d7-4908-eb71-6e1a085d8c36"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<NgrokTunnel: \"http://ab46-104-155-214-185.ngrok.io\" -> \"http://localhost:80\">"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "public_url"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9jcxgCgkui45"
      },
      "outputs": [],
      "source": [
        "ngrok.kill()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The code is using the Flask framework to create a web application. The user can upload a video file using a form, which is then saved to the server. The video file is then processed to extract 22 frames from the video using OpenCV. The frames are then cropped to only show the mouth using the Dlib library. The cropped frames are saved to a directory on the server where they are again loaded and passed through the model to predict the class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R8Bv40Yg5XPH"
      },
      "outputs": [],
      "source": [
        "from flask import Flask, render_template\n",
        "from flask_wtf import FlaskForm\n",
        "from wtforms import FileField, SubmitField\n",
        "from werkzeug.utils import secure_filename\n",
        "import os\n",
        "from wtforms.validators import InputRequired\n",
        "# from moviepy.editor import VideoFileClip\n",
        "import numpy as np\n",
        "import os\n",
        "import imutils\n",
        "import dlib\n",
        "import math\n",
        "import cv2 \n",
        "import imageio\n",
        "from imutils import face_utils\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.models import load_model\n",
        "from skimage.transform import resize\n",
        "import time\n",
        "\n",
        "\n",
        "# extracing frames from video using openCV\n",
        "# limiting the frames to 22\n",
        "def extract_frames(video_file,dir):\n",
        "    vidcap = cv2.VideoCapture(video_file)\n",
        "\n",
        "    # The function returns a Boolean value indicating if the frame/s was successfully read and an image matrix. \n",
        "    success, image = vidcap.read()\n",
        "    idx = 0\n",
        "\n",
        "    # Retrieves the total number of frames. The argument \"cv2.CAP_PROP_FRAME_COUNT\" specifies the property to be retrieved.\n",
        "    possible_frames = vidcap.get(cv2.CAP_PROP_FRAME_COUNT)\n",
        "    gap = math.floor(possible_frames/22)\n",
        "    os.makedirs(dir,exist_ok=True)\n",
        "    print(gap)\n",
        "    i = 0\n",
        "    success, image = vidcap.read()\n",
        "    while success:\n",
        "      # limiting to 22 frames\n",
        "        if(idx % gap == 0):\n",
        "            cv2.imwrite(f\"{dir}/frame{i:03d}.png\", image)\n",
        "            i += 1\n",
        "        success, image = vidcap.read()\n",
        "        if(i == 22 ):\n",
        "            break\n",
        "        idx += 1\n",
        "\n",
        "app = Flask(__name__,template_folder='templates')\n",
        "app.config['SECRET_KEY'] = 'supersecretkey'\n",
        "app.config['UPLOAD_FOLDER'] = 'static/files'\n",
        "\n",
        "class UploadFileForm(FlaskForm):\n",
        "    file = FileField(\"File\", validators=[InputRequired()])\n",
        "    submit = SubmitField(\"Upload File\")\n",
        "\n",
        "@app.route('/', methods=['GET',\"POST\"])\n",
        "@app.route('/home', methods=['GET',\"POST\"])\n",
        "def home():\n",
        "    form = UploadFileForm()\n",
        "    if form.validate_on_submit():\n",
        "        file = form.file.data # First grab the file\n",
        "        file.save('/content/static/files/previous.mp4') # Then save the file\n",
        "        print('video saved')\n",
        "        \n",
        "        # extracting frames\n",
        "  \n",
        "        f_directory = '/content/static/frames'\n",
        "        video_path = '/content/static/files/previous.mp4'\n",
        "        extract_frames(video_path, f_directory)\n",
        "        # to avoid getting names of other files such as .ipynb_checkpoint\n",
        "        file_list = [_ for _ in os.listdir('/content/static/frames') if _.endswith('.png')]\n",
        "        # os.chdir('../../')\n",
        "\n",
        "        def crop_and_save_image(img, img_path, write_img_path, img_name):\n",
        "            detector = dlib.get_frontal_face_detector()\n",
        "            predictor = dlib.shape_predictor('/content/drive/MyDrive/datasets/shape_predictor_68_face_landmarks/shape_predictor_68_face_landmarks.dat')\n",
        "            # load the input image, resize it, and convert it to grayscale\n",
        "\n",
        "            image = cv2.imread(img_path)\n",
        "            image = imutils.resize(image, width=500)\n",
        "            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "            # detect faces in the grayscale image\n",
        "            rects = detector(gray, 1)\n",
        "            if len(rects) > 1:\n",
        "                print(\"Error\")\n",
        "                return\n",
        "            if len(rects) < 1:\n",
        "                print( \"ERROR: no faces detected\")\n",
        "                return\n",
        "            for (i, rect) in enumerate(rects):\n",
        "                shape = predictor(gray, rect)\n",
        "                shape = face_utils.shape_to_np(shape)\n",
        "                name, i, j = 'mouth', 48, 68\n",
        "                # clone = gray.copy()\n",
        "                (x, y, w, h) = cv2.boundingRect(np.array([shape[i:j]]))        \n",
        "                roi = gray[y:y+h, x:x+w]\n",
        "                roi = imutils.resize(roi, width = 250, inter=cv2.INTER_CUBIC)        \n",
        "                print( write_img_path)\n",
        "                cv2.imwrite(write_img_path, roi)\n",
        "\n",
        "        # os.mkdir('/content/static/cropped')\n",
        "        os.makedirs('/content/static/cropped/', exist_ok=True)\n",
        "        directory = '/content/static/frames/'\n",
        "        dir_temp = '/content/static/cropped/'\n",
        "        print('cropping frames')\n",
        "        for img_name in file_list:\n",
        "            image = imageio.imread(directory + '' + img_name)\n",
        "            crop_and_save_image(image, directory + '' + img_name,dir_temp + '' + img_name, img_name)\n",
        "\n",
        "        print('loading model')\n",
        "        savedModel=load_model('/content/drive/MyDrive/models/cnn_adagrad_e45_bc16/model.h5')\n",
        "\n",
        "        # preprocessing the cropped image\n",
        "        max_seq_length = 22\n",
        "        MAX_WIDTH = 100\n",
        "        MAX_HEIGHT = 100\n",
        "\n",
        "\n",
        "        sequence = []\n",
        "        for img_name in file_list:        \n",
        "            image = imageio.imread(dir_temp + '/' + img_name)\n",
        "            image = resize(image, (MAX_WIDTH, MAX_HEIGHT))\n",
        "            image = 255 * image\n",
        "            # Convert to integer data type pixels.\n",
        "            image = image.astype(np.uint8)\n",
        "            sequence.append(image)                        \n",
        "        pad_array = [np.zeros((MAX_WIDTH, MAX_HEIGHT))]                            \n",
        "        sequence.extend(pad_array * (max_seq_length - len(sequence)))\n",
        "        sequence = np.array(sequence)\n",
        "\n",
        "        def normalize_it(X):\n",
        "            v_min = X.min(axis=(2, 3), keepdims=True)\n",
        "            v_max = X.max(axis=(2, 3), keepdims=True)\n",
        "            X = (X - v_min)/(v_max - v_min)\n",
        "            X = np.nan_to_num(X)\n",
        "            return X\n",
        "\n",
        "        \n",
        "        # making prediction\n",
        "        X_test = []\n",
        "        X_test.append(sequence)\n",
        "        X_test = np.array(X_test)\n",
        "        X_test = normalize_it(X_test)\n",
        "        X_test = np.expand_dims(X_test, axis=4)\n",
        "        ypred = savedModel.predict(X_test)\n",
        "        words = ['Begin', 'Choose', 'Connection', 'Navigation', 'Next', 'Previous', 'Start', 'Stop', 'Hello', 'Web']  \n",
        "        predicted_words = [words[i] for i in np.argmax(ypred, axis=1)]\n",
        "        print(predicted_words) \n",
        "        os.system(\"rm -rf /content/static/cropped\")\n",
        "        os.system(\"rm -rf /content/static/frames\")\n",
        "        return predicted_words[0]\n",
        "\n",
        "    return render_template('index.html', form=form)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "RTRNRugk5YT9",
        "outputId": "3d504ebf-a259-4b90-e9d7-614ae2fe2452"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " * Serving Flask app \"__main__\" (lazy loading)\n",
            " * Environment: production\n",
            "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
            "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
            " * Debug mode: on\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:werkzeug: * Running on http://127.0.0.1:80/ (Press CTRL+C to quit)\n",
            "INFO:werkzeug:127.0.0.1 - - [10/Nov/2022 09:43:08] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [10/Nov/2022 09:43:09] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n",
            "INFO:werkzeug:127.0.0.1 - - [10/Nov/2022 09:56:26] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [10/Nov/2022 09:56:27] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n"
          ]
        }
      ],
      "source": [
        "app.run(debug=True,use_reloader=False,port=80)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A8JPpNgMF8UF"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
